{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7d35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be383aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"VGGFace2_balanced_900_albumentations\"\n",
    "IMAGE_SIZE = (224, 224)   # ResNet input\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1287494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.02) \n",
    "])\n",
    "\n",
    "\n",
    "# Load class names\n",
    "class_names = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])\n",
    "class_to_int = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Process image function\n",
    "def process_path(file_path):\n",
    "    class_name = tf.strings.split(file_path, os.path.sep)[-2]\n",
    "    label = tf.py_function(lambda x: class_to_int[x.numpy().decode()], [class_name], tf.int32)\n",
    "    label.set_shape([])\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    return img, label\n",
    "\n",
    "# Configure dataset performance\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=3000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Get all image paths\n",
    "all_image_paths = [os.path.join(dp, f) \n",
    "                   for dp, dn, fn in os.walk(os.path.expanduser(DATASET_PATH)) \n",
    "                   for f in fn]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "# Split train/val/test\n",
    "total_images = len(all_image_paths)\n",
    "train_size = int(0.7 * total_images)\n",
    "val_size = int(0.15 * total_images)\n",
    "train_paths = all_image_paths[:train_size]\n",
    "val_paths = all_image_paths[train_size:train_size + val_size]\n",
    "test_paths = all_image_paths[train_size + val_size:]\n",
    "\n",
    "# Build datasets\n",
    "train_ds = configure_for_performance(tf.data.Dataset.from_tensor_slices(train_paths).map(process_path, num_parallel_calls=tf.data.AUTOTUNE))\n",
    "val_ds = configure_for_performance(tf.data.Dataset.from_tensor_slices(val_paths).map(process_path, num_parallel_calls=tf.data.AUTOTUNE))\n",
    "test_ds = configure_for_performance(tf.data.Dataset.from_tensor_slices(test_paths).map(process_path, num_parallel_calls=tf.data.AUTOTUNE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a650fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,  \n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base_model.trainable = False  # Freeze convolutional layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ddf333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.layers.Lambda(preprocess_input)(x)  \n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fade1cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m3,855\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,116,111</span> (92.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,116,111\u001b[0m (92.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,399</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m528,399\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a55e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, min_lr=1e-7, verbose=1)\n",
    "checkpoint = ModelCheckpoint('resnet_transfer.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a857415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2037 - loss: 2.4191\n",
      "Epoch 1: val_accuracy improved from None to 0.55407, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 2s/step - accuracy: 0.3003 - loss: 2.0460 - val_accuracy: 0.5541 - val_loss: 1.4168 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.4892 - loss: 1.4625\n",
      "Epoch 2: val_accuracy improved from 0.55407 to 0.65086, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 2s/step - accuracy: 0.5244 - loss: 1.3823 - val_accuracy: 0.6509 - val_loss: 1.1062 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6049 - loss: 1.1613\n",
      "Epoch 3: val_accuracy improved from 0.65086 to 0.71951, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 2s/step - accuracy: 0.6250 - loss: 1.1213 - val_accuracy: 0.7195 - val_loss: 0.9104 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6685 - loss: 0.9828\n",
      "Epoch 4: val_accuracy improved from 0.71951 to 0.75358, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 2s/step - accuracy: 0.6776 - loss: 0.9665 - val_accuracy: 0.7536 - val_loss: 0.8063 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7073 - loss: 0.8582\n",
      "Epoch 5: val_accuracy improved from 0.75358 to 0.75457, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 2s/step - accuracy: 0.7125 - loss: 0.8629 - val_accuracy: 0.7546 - val_loss: 0.7677 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7384 - loss: 0.7918\n",
      "Epoch 6: val_accuracy improved from 0.75457 to 0.79210, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 2s/step - accuracy: 0.7332 - loss: 0.7970 - val_accuracy: 0.7921 - val_loss: 0.6864 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7678 - loss: 0.7024\n",
      "Epoch 7: val_accuracy improved from 0.79210 to 0.80889, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 2s/step - accuracy: 0.7675 - loss: 0.7177 - val_accuracy: 0.8089 - val_loss: 0.6386 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7796 - loss: 0.6790\n",
      "Epoch 8: val_accuracy improved from 0.80889 to 0.81728, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 2s/step - accuracy: 0.7743 - loss: 0.6825 - val_accuracy: 0.8173 - val_loss: 0.6172 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7980 - loss: 0.6473\n",
      "Epoch 9: val_accuracy did not improve from 0.81728\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 3s/step - accuracy: 0.7880 - loss: 0.6545 - val_accuracy: 0.8099 - val_loss: 0.5991 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8001 - loss: 0.6190\n",
      "Epoch 10: val_accuracy improved from 0.81728 to 0.82716, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 3s/step - accuracy: 0.8034 - loss: 0.6097 - val_accuracy: 0.8272 - val_loss: 0.5750 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8044 - loss: 0.5847\n",
      "Epoch 11: val_accuracy improved from 0.82716 to 0.82765, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 3s/step - accuracy: 0.8052 - loss: 0.5947 - val_accuracy: 0.8277 - val_loss: 0.5607 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8124 - loss: 0.5756\n",
      "Epoch 12: val_accuracy did not improve from 0.82765\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 2s/step - accuracy: 0.8114 - loss: 0.5739 - val_accuracy: 0.8212 - val_loss: 0.5620 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8252 - loss: 0.5374\n",
      "Epoch 13: val_accuracy improved from 0.82765 to 0.84395, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 2s/step - accuracy: 0.8202 - loss: 0.5499 - val_accuracy: 0.8440 - val_loss: 0.5233 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8279 - loss: 0.5179\n",
      "Epoch 14: val_accuracy did not improve from 0.84395\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 2s/step - accuracy: 0.8239 - loss: 0.5303 - val_accuracy: 0.8395 - val_loss: 0.5177 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8325 - loss: 0.5167\n",
      "Epoch 15: val_accuracy did not improve from 0.84395\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 2s/step - accuracy: 0.8321 - loss: 0.5140 - val_accuracy: 0.8415 - val_loss: 0.5100 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8447 - loss: 0.4848\n",
      "Epoch 16: val_accuracy improved from 0.84395 to 0.84444, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 2s/step - accuracy: 0.8453 - loss: 0.4826 - val_accuracy: 0.8444 - val_loss: 0.4955 - learning_rate: 5.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8505 - loss: 0.4731\n",
      "Epoch 17: val_accuracy did not improve from 0.84444\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m744s\u001b[0m 3s/step - accuracy: 0.8472 - loss: 0.4750 - val_accuracy: 0.8410 - val_loss: 0.4898 - learning_rate: 5.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8533 - loss: 0.4576\n",
      "Epoch 18: val_accuracy improved from 0.84444 to 0.85037, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1970s\u001b[0m 7s/step - accuracy: 0.8549 - loss: 0.4589 - val_accuracy: 0.8504 - val_loss: 0.4852 - learning_rate: 5.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8561 - loss: 0.4558\n",
      "Epoch 19: val_accuracy improved from 0.85037 to 0.85235, saving model to resnet_transfer.keras\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 2s/step - accuracy: 0.8564 - loss: 0.4544 - val_accuracy: 0.8523 - val_loss: 0.4801 - learning_rate: 5.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8546 - loss: 0.4385\n",
      "Epoch 20: val_accuracy did not improve from 0.85235\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 2s/step - accuracy: 0.8501 - loss: 0.4507 - val_accuracy: 0.8519 - val_loss: 0.4733 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9374002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"resnet_transfer_weights.weights.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
