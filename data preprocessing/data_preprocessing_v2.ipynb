{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bddaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c96756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the first thing we did is that we took the biggest 15 classes of our original dataset and then resizing its images and then putting them in a whole new directiry\n",
    "to not alter/change the original dataset, to avoid any error :)\n",
    "\"\"\"\n",
    "\n",
    "DATASET_PATH = \"dataset/VGGFace2/VGGFace2\"\n",
    "\n",
    "# thats the path of the final desired dataset we would like to use in our models\n",
    "OUTPUT_DATASET_PATH = \"dataset/VGGFace2_top15_classes\"\n",
    "NUM_CLASSES_TO_SELECT = 15\n",
    "\n",
    "# ofcourse we need to resize all the images to be the same size to help the model to learn\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "\"\"\"\n",
    "ofcourse we need our dataset to be balanced meaning that each class/folder must have same number of images to let the model not to be biased to a certain class\n",
    "so we need this function to count the number of images in each class and return a dictionary containing each class with its number of images insde it\n",
    "\"\"\"\n",
    "def get_class_image_counts(dataset_path):\n",
    "    class_counts = {}\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        print(f\"Error: Dataset path not found - {dataset_path}\")\n",
    "        return class_counts\n",
    "\n",
    "    # we used tqdm for a progress bar\n",
    "    class_folders = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    print(f\"Scanning {len(class_folders)} class folders...\")\n",
    "\n",
    "    for class_name in tqdm(class_folders, desc=\"Scanning classes\"):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        if num_images > 0:\n",
    "            class_counts[class_name] = num_images\n",
    "    return class_counts\n",
    "\n",
    "\"\"\"\n",
    "we had to use only 15 classes out of 400 and something class because that number was very huge and our poor laptops would take ages until they train the models\n",
    "and get a good accuracy on that kind of huge dataset, we have tried it already and it took more than 3 days and we ony got accuracy of 0.02% :') so dissapointing\n",
    "also we need to pick the classes that have the biggest number of images to let our model learn very well, thats why this function is here\n",
    "\"\"\"\n",
    "def select_top_classes(class_counts, num_classes):\n",
    "    if not class_counts:\n",
    "        print(\"No classes found to select from.\")\n",
    "        return []\n",
    "\n",
    "    # here we sort the classes accprding to the `operator.itemgetter(1)` means the second element of each tuple inside the dict => num_of_images\n",
    "    sorted_classes = sorted(class_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    # her we pick the top15 classes names, `sorted_classes[:num_classes]` means we take only the first 15 elements in this dict, and then we take the name of each class of them\n",
    "    top_n_class_names = [class_name for class_name, count in sorted_classes[:num_classes]]\n",
    "\n",
    "    return top_n_class_names\n",
    "\n",
    "# --- 3. Preprocess and Save Images for Selected Classes ---\n",
    "\n",
    "def preprocess_and_save_images(dataset_path, output_path, selected_classes, image_size):\n",
    "    # here we check if the output_path/output_dataset_path exists or not, so if it exists we will remove it ofcourse, since we don't want any inconsistency in our data\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output directory {output_path} already exists. Removing it.\")\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "    print(f\"\\nProcessing and saving images for {len(selected_classes)} selected classes...\")\n",
    "\n",
    "    # here we know that each class in the `selected_classes` is a celebrity in our original dataset, so we want to create the same set of folders/celebrities in our output_dataset as well\n",
    "    for class_name in tqdm(selected_classes, desc=\"Processing images\"):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        # here we collect all the image names that ofcourse are ending with .png or bla bla and putting them in one list for easily catching them\n",
    "        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "        for image_name in image_files:\n",
    "            try:\n",
    "                # getting the whole image's path in our original dataset\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                with Image.open(image_path) as img:\n",
    "\n",
    "                    # resizing the image\n",
    "                    img_resized = img.resize(image_size, Image.LANCZOS)\n",
    "                    \n",
    "                    # some models expect to train on RGB colors so better convert them into it, ugh remembered multimedia TwT\n",
    "                    if img_resized.mode != 'RGB':\n",
    "                        img_resized = img_resized.convert('RGB')\n",
    "                    \n",
    "                    # yo smarty, don't forget to save these resulted images in our output_dataset okee, or all what we did will just evaborate ^_^\n",
    "                    output_image_path = os.path.join(output_class_path, image_name)\n",
    "                    img_resized.save(output_image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "    print(\"\\nImage preprocessing complete.\")\n",
    "    print(f\"Processed dataset is saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 469 class folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning classes: 100%|██████████| 469/469 [00:03<00:00, 148.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 classes selected:\n",
      "1. Class: Alexa Chung, Images: 720\n",
      "2. Class: Amy Adams, Images: 689\n",
      "3. Class: Alex Salmond, Images: 676\n",
      "4. Class: Andie MacDowell, Images: 658\n",
      "5. Class: Alberto Núñez Feijóo, Images: 648\n",
      "6. Class: Bronisław Komorowski, Images: 644\n",
      "7. Class: Alesha Dixon, Images: 639\n",
      "8. Class: Aleksander Kwaśniewski, Images: 623\n",
      "9. Class: Alfredo Pérez Rubalcaba, Images: 617\n",
      "10. Class: Aléxis Tsípras, Images: 613\n",
      "11. Class: Amber Heard, Images: 605\n",
      "12. Class: Adrienne Bailon-Houghton, Images: 603\n",
      "13. Class: Aleksandra Kwaśniewska, Images: 596\n",
      "14. Class: Aditi Rao Hydari, Images: 594\n",
      "15. Class: Boris Tadić, Images: 594\n",
      "\n",
      "Processing and saving images for 15 selected classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 15/15 [03:30<00:00, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image preprocessing complete.\n",
      "Processed dataset is saved at: dataset/VGGFace2_top15_classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lets test these functions out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_class_counts = get_class_image_counts(DATASET_PATH)\n",
    "    if all_class_counts:\n",
    "        top_classes = select_top_classes(all_class_counts, NUM_CLASSES_TO_SELECT)\n",
    "        print(f\"\\nTop {NUM_CLASSES_TO_SELECT} classes selected:\")\n",
    "        for i, class_name in enumerate(top_classes):\n",
    "            print(f\"{i+1}. Class: {class_name}, Images: {all_class_counts[class_name]}\")\n",
    "        preprocess_and_save_images(DATASET_PATH, OUTPUT_DATASET_PATH, top_classes, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329259d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thats the dataset we just created that has the top15 classes\n",
    "INPUT_DATASET_PATH = \"dataset/VGGFace2_top15_classes\"\n",
    "\n",
    "# thats the final desired dataset that is balanced and preprocessed\n",
    "BALANCED_DATASET_PATH = \"dataset/VGGFace2_balanced_900_albumentations\"\n",
    "\n",
    "# thats the number of images we need in each class\n",
    "TARGET_COUNT = 900\n",
    "\n",
    "\"\"\"if we found out that a class needs more images so what we do? we should add new augmented images of randomly selected images of our class, so confusing but\n",
    "read it again and you will understand :), all thgese things we do is to FAKELY create new images, so more data more learning \n",
    "\"\"\"\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),    # probability of 50%\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1,\n",
    "        scale_limit=0.1,\n",
    "        rotate_limit=10,\n",
    "        p=0.8                   # probability of 80%\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.5),   # probability of 50%\n",
    "])\n",
    "\n",
    "\n",
    "# this function's name already explains itself so no need for me to tire myself by explaining it..\n",
    "def balance_dataset_to_target(input_path, output_path, target_count):\n",
    "    # checking if the `output_path` meaning the balanced datasetalready exixts? if it exists then removed because we don't need errors anymore\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"Output directory {output_path} already exists. Removing it.\")\n",
    "        shutil.rmtree(output_path)\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Balancing all classes to a target of {target_count} images per class.\\n\")\n",
    "\n",
    "    # here we get a list of all the folders/celebrities names inside our original dataset\n",
    "    class_folders = [d for d in os.listdir(input_path) if os.path.isdir(os.path.join(input_path, d))]\n",
    "\n",
    "    # here we loop on each folder/celebrity and get its name to be ble to create the same folder in the output dataset\n",
    "    for class_name in tqdm(class_folders, desc=\"Balancing classes\"):\n",
    "        input_class_path = os.path.join(input_path, class_name)\n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        image_files = os.listdir(input_class_path)\n",
    "        current_count = len(image_files)\n",
    "        \n",
    "        if current_count == 0:\n",
    "            continue\n",
    "\n",
    "        # here we copy all the images in the original dataset's folder and paste them in the same folder created in our output dataset\n",
    "        for image_name in image_files:\n",
    "            shutil.copy(os.path.join(input_class_path, image_name), os.path.join(output_class_path, image_name))\n",
    "\n",
    "        # here we check if the number of images in the class size is less than 900 if its less than that then we need to balance it :)\n",
    "        if current_count < target_count:\n",
    "            num_to_generate = target_count - current_count\n",
    "            # here we collect all the image paths inside that class that need tio be balanced\n",
    "            image_paths_to_sample = [os.path.join(input_class_path, f) for f in image_files]\n",
    "\n",
    "            # we need to generate `num_to_generate` number of images to make our output dataset balanced\n",
    "            for i in range(num_to_generate):\n",
    "                # we pick a random image to not be biased to anyone\n",
    "                random_image_path = random.choice(image_paths_to_sample)\n",
    "                \n",
    "                try:\n",
    "                    # here we had to read the image using cv2 that reads images as BGR NumPy arrays\n",
    "                    img_array = cv2.imread(random_image_path)\n",
    "\n",
    "                    # here we needed to convert BGR to RGB since many models expect RGB as i said before\n",
    "                    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    # now the step that we waited long time to reach to, the augmentation! here the real manipulation happens to create FAKELY new images\n",
    "                    augmented = augmentation_pipeline(image=img_array)\n",
    "                    augmented_image_array = augmented['image']\n",
    "                    \n",
    "                    # convert it back to BGR to save with cv2\n",
    "                    augmented_image_bgr = cv2.cvtColor(augmented_image_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # here is the step that we wanna save our augmented image\n",
    "                    new_image_name = f\"aug_{i}_{os.path.basename(random_image_path)}\"\n",
    "                    output_image_path = os.path.join(output_class_path, new_image_name)\n",
    "                    cv2.imwrite(output_image_path, augmented_image_bgr)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError augmenting image {random_image_path}: {e}\")\n",
    "\n",
    "    print(\"\\nDataset balancing complete!\")\n",
    "    print(f\"New balanced dataset is located at: {BALANCED_DATASET_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657d8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing all classes to a target of 900 images per class.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing classes: 100%|██████████| 15/15 [04:56<00:00, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset balancing complete!\n",
      "New balanced dataset is located at: dataset/VGGFace2_balanced_900_albumentations\n",
      "\n",
      "Verifying image counts in the new balanced dataset:\n",
      "- Aditi Rao Hydari: 900 images\n",
      "- Adrienne Bailon-Houghton: 900 images\n",
      "- Alberto Núñez Feijóo: 900 images\n",
      "- Aleksander Kwaśniewski: 900 images\n",
      "- Aleksandra Kwaśniewska: 900 images\n",
      "- Alesha Dixon: 900 images\n",
      "- Alex Salmond: 900 images\n",
      "- Alexa Chung: 900 images\n",
      "- Alfredo Pérez Rubalcaba: 900 images\n",
      "- Aléxis Tsípras: 900 images\n",
      "- Amber Heard: 900 images\n",
      "- Amy Adams: 900 images\n",
      "- Andie MacDowell: 900 images\n",
      "- Boris Tadić: 900 images\n",
      "- Bronisław Komorowski: 900 images\n",
      "\n",
      "Success! All classes are perfectly balanced.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lets test all this out\n",
    "if __name__ == '__main__':\n",
    "    balance_dataset_to_target(INPUT_DATASET_PATH, BALANCED_DATASET_PATH, TARGET_COUNT)\n",
    "    print(\"\\nVerifying image counts in the new balanced dataset:\")\n",
    "    all_balanced = True\n",
    "    for class_name in os.listdir(BALANCED_DATASET_PATH):\n",
    "        count = len(os.listdir(os.path.join(BALANCED_DATASET_PATH, class_name)))\n",
    "        print(f\"- {class_name}: {count} images\")\n",
    "        if count != TARGET_COUNT:\n",
    "            all_balanced = False\n",
    "    \n",
    "    if all_balanced:\n",
    "        print(\"\\nSuccess! All classes are perfectly balanced.\")\n",
    "    else:\n",
    "        print(\"\\nWarning: Some classes did not reach the target count.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration and Setup ---\n",
    "# Point to your balanced dataset with 900 images per class\n",
    "BALANCED_DATASET_PATH = \"dataset/VGGFace2_balanced_900_albumentations\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 15\n",
    "# The official TF Hub handle for the InceptionV1 model\n",
    "TFHUB_MODEL_HANDLE = \"https://tfhub.dev/google/imagenet/inception_v1/feature_vector/5\"\n",
    "\n",
    "# --- 2. Create a Dataset of all File Paths and Shuffle ---\n",
    "# This is the most memory-efficient way to handle a large dataset.\n",
    "# We work with file paths first, not the actual image data.\n",
    "\n",
    "# Get a list of all image file paths\n",
    "all_image_paths = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(BALANCED_DATASET_PATH)) for f in fn]\n",
    "# Shuffle the paths randomly. This is a critical step.\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "total_images = len(all_image_paths)\n",
    "print(f\"Found {total_images} total images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
